Network architecture:

-----------------------------------------------------------------------
EXPERIMENTAL PARAMETER:
-----------------------------------------------------------------------

Gradient estimation: Adam, RMSprop


-----------------------------------------------------------------------
CONSTANT PARAMETERS:
-----------------------------------------------------------------------
MLP layer activation: Softmax
Convolutional layers: 3
Dense layers = 1
alpha = 0.4
no_of_classes = 3
no_of_conv_filters = 256
filter_size = 5
pool_size = 3
hidden_units_mlp = 64
kernel / weight initializer = random normal
activation = RELU
loss function = categorical cross_entropy
metrics = ['accuracy', 'mse']
batch_size = 10
epochs = 5


-----------------------------------------------------------------------
OBSERVATIONS:
-----------------------------------------------------------------------

No significant improvement in observations again. Both gradient estimations 
give 33.33% accuracy.  
